# Reinforcement Learning Fundamentals â€” Companion Code

[![Python (Chapters)](https://github.com/srikanthbaride/Reinforcement-Learning-Fundamentals-Code/actions/workflows/python-tests.yml/badge.svg?branch=main)](https://github.com/srikanthbaride/Reinforcement-Learning-Fundamentals-Code/actions/workflows/python-tests.yml)


This repository hosts **chapter-wise companion code** for the book *Reinforcement Learning Fundamentals: From Theory to Practice*.  
It provides clean, minimal, and well-tested implementations of key reinforcement learning concepts.

---

## ğŸ“‚ Repository Structure

```
rl-fundamentals-code/
â”œâ”€ ch2_rl_formulation/              # Chapter 2: The RL Problem Formulation
â”‚  â”œâ”€ gridworld.py                  # 4x4 GridWorld MDP (tabular P,R builder)
â”‚  â”œâ”€ evaluation.py                 # Policy evaluation, q_from_v(), greedy_from_q()
â”‚  â”œâ”€ policies.py                   # Deterministic & Îµ-greedy policies
â”‚  â”œâ”€ value_iteration.py            # Bellman optimality, value iteration
â”‚  â”œâ”€ examples/                     # Numeric examples, GridWorld demo, plotting
â”‚  â””â”€ tests/                        # Pytest-based checks for chapter numbers
â”‚
â”œâ”€ ch3_multi_armed_bandits/         # Chapter 3: Multi-Armed Bandits
â”‚  â”œâ”€ bandits.py                    # Bernoulli & Gaussian bandit environments
â”‚  â”œâ”€ epsilon_greedy.py             # Sample-average Îµ-greedy agent
â”‚  â”œâ”€ ucb.py                        # UCB1 agent (with tunable exploration constant)
â”‚  â”œâ”€ thompson.py                   # Betaâ€“Bernoulli Thompson Sampling agent
â”‚  â”œâ”€ experiments.py                # Run algorithms, generate regret plots
â”‚  â”œâ”€ plots/                        # Saved figures (regret_bernoulli.png, etc.)
â”‚  â””â”€ tests/                        # Regression tests (ordering, sublinear regret)
â”‚
â”œâ”€ utils/                           # Shared helper utilities (future use)
â”‚
â”œâ”€ .github/workflows/               # CI: runs pytest on every push/PR
â”‚  â””â”€ python-tests.yml
â”‚
â”œâ”€ requirements.txt                 # Global dependencies (numpy, matplotlib, pytest)
â”œâ”€ requirements_ch2.txt             # Chapter 2â€“specific dependencies
â”œâ”€ requirements_ch3.txt             # Chapter 3â€“specific dependencies
â””â”€ README.md                        # Project overview + usage

```

---

## ğŸš€ Getting Started

Clone this repository:

```bash
git clone https://github.com/srikanthbaride/Reinforcement-Learning-Fundamentals-Code.git
cd Reinforcement-Learning-Fundamentals-Code
```

Set up a virtual environment (recommended):

```bash
python -m venv .venv
source .venv/bin/activate   # Linux/macOS
.\.venv\Scriptsctivate    # Windows PowerShell
```

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## âœ… Running Tests

To run all tests:

```bash
python -m pytest -q
```

To run only Chapter 2 tests:

```bash
python -m pytest -q ch2_rl_formulation/tests
```

---

## ğŸ§ª Examples

Run numeric checks for Chapter 2:

```bash
python -m ch2_rl_formulation.examples.numeric_checks
```

Run the GridWorld demo:

```bash
python -m ch2_rl_formulation.examples.gridworld_demo
```

---

## âš™ï¸ Continuous Integration

- GitHub Actions (`.github/workflows/python-tests.yml`) automatically run tests for all chapters on every push and pull request.
- This ensures correctness and reproducibility of the examples.

---

## ğŸ“– License

MIT License Â© 2025 â€” Srikanth Baride
